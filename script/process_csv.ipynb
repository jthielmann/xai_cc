{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-12T11:04:13.697884Z",
     "start_time": "2024-08-12T11:04:11.589265Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from data_loader import get_patient_loader\n",
    "import torch\n",
    "from model import get_models_and_path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T11:04:13.711950Z",
     "start_time": "2024-08-12T11:04:13.699042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "data_dir_test = \"../Test_Data/\"\n",
    "data_dir_train = \"../Training_Data/\"\n",
    "patients_test  = [os.path.basename(f) for f in os.scandir(data_dir_test) if f.is_dir()]\n",
    "patients_train = [os.path.basename(f) for f in os.scandir(data_dir_train) if f.is_dir()]\n",
    "print(patients_test)\n",
    "print(patients_train)\n",
    "\n",
    "results_dir = \"../results/\"\n",
    "gene = \"RUBCNL\""
   ],
   "id": "c506d37ba4fb2651",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p021', 'p026', 'p008']\n",
      "['p020', 'p016', 'p014', 'p013', 'p025', 'p007', 'p009']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T11:04:17.084887Z",
     "start_time": "2024-08-12T11:04:13.712743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# list of (model, path to .pt file)\n",
    "models = get_models_and_path(device)\n"
   ],
   "id": "1831b867a2fb0645",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# list of (model, path to .pt file)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m models \u001B[38;5;241m=\u001B[39m \u001B[43mget_models_and_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/uni/Master/master thesis/sync/xai_cc/script/model.py:234\u001B[0m, in \u001B[0;36mget_models_and_path\u001B[0;34m(device, log_model_name)\u001B[0m\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m log_model_name:\n\u001B[1;32m    233\u001B[0m         \u001B[38;5;28mprint\u001B[39m(r[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m--> 234\u001B[0m     models\u001B[38;5;241m.\u001B[39mappend((\u001B[43mr\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39meval(), r[\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m models\n",
      "File \u001B[0;32m~/Documents/uni/Master/master thesis/sync/xai_cc/script/model.py:206\u001B[0m, in \u001B[0;36mget_vgg13\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_vgg13\u001B[39m(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 206\u001B[0m     vgg13 \u001B[38;5;241m=\u001B[39m \u001B[43mVGG13\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m path:\n\u001B[1;32m    208\u001B[0m         \u001B[38;5;28mprint\u001B[39m(vgg13\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(path, map_location\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m))))\n",
      "File \u001B[0;32m~/Documents/uni/Master/master thesis/sync/xai_cc/script/model.py:198\u001B[0m, in \u001B[0;36mVGG13.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28msuper\u001B[39m(VGG13, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m--> 198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpretrained \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvgg13\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mIMAGENET1K_V1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgene1 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;241m1000\u001B[39m, \u001B[38;5;241m200\u001B[39m), nn\u001B[38;5;241m.\u001B[39mDropout(), nn\u001B[38;5;241m.\u001B[39mReLU(), nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[38;5;241m200\u001B[39m, \u001B[38;5;241m1\u001B[39m), nn\u001B[38;5;241m.\u001B[39mDropout())\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/models/_utils.py:142\u001B[0m, in \u001B[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    135\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    136\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msequence_to_str(\u001B[38;5;28mtuple\u001B[39m(keyword_only_kwargs\u001B[38;5;241m.\u001B[39mkeys()), separate_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand \u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m as positional \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    138\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minstead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    139\u001B[0m     )\n\u001B[1;32m    140\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mupdate(keyword_only_kwargs)\n\u001B[0;32m--> 142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/models/_utils.py:228\u001B[0m, in \u001B[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m kwargs[pretrained_param]\n\u001B[1;32m    226\u001B[0m     kwargs[weights_param] \u001B[38;5;241m=\u001B[39m default_weights_arg\n\u001B[0;32m--> 228\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbuilder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/models/vgg.py:381\u001B[0m, in \u001B[0;36mvgg13\u001B[0;34m(weights, progress, **kwargs)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;124;03m\"\"\"VGG-13 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\u001B[39;00m\n\u001B[1;32m    362\u001B[0m \n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;124;03m    :members:\u001B[39;00m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    379\u001B[0m weights \u001B[38;5;241m=\u001B[39m VGG13_Weights\u001B[38;5;241m.\u001B[39mverify(weights)\n\u001B[0;32m--> 381\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_vgg\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/models/vgg.py:105\u001B[0m, in \u001B[0;36m_vgg\u001B[0;34m(cfg, batch_norm, weights, progress, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m model \u001B[38;5;241m=\u001B[39m VGG(make_layers(cfgs[cfg], batch_norm\u001B[38;5;241m=\u001B[39mbatch_norm), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 105\u001B[0m     model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mweights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprogress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/models/_api.py:90\u001B[0m, in \u001B[0;36mWeightsEnum.get_state_dict\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state_dict\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Mapping[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m---> 90\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_state_dict_from_url\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/hub.py:764\u001B[0m, in \u001B[0;36mload_state_dict_from_url\u001B[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001B[0m\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_legacy_zip_format(cached_file):\n\u001B[1;32m    763\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n\u001B[0;32m--> 764\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcached_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights_only\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:1025\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1023\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1024\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m-> 1025\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m                     \u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverall_storage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[1;32m   1031\u001B[0m     f_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:1446\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1444\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1445\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m-> 1446\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1448\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m   1449\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[1;32m   1450\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[1;32m   1451\u001B[0m )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:1416\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m   1414\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1415\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[0;32m-> 1416\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1418\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:1381\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(dtype, numel, key, location)\u001B[0m\n\u001B[1;32m   1379\u001B[0m     storage \u001B[38;5;241m=\u001B[39m overall_storage[storage_offset:storage_offset \u001B[38;5;241m+\u001B[39m numel]\n\u001B[1;32m   1380\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1381\u001B[0m     storage \u001B[38;5;241m=\u001B[39m \u001B[43mzip_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_storage_from_record\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mUntypedStorage\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_untyped_storage\n\u001B[1;32m   1382\u001B[0m \u001B[38;5;66;03m# swap here if byteswapping is needed\u001B[39;00m\n\u001B[1;32m   1383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m byteorderdata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T11:04:17.086015Z",
     "start_time": "2024-08-12T11:04:17.085939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "for patient in patients_test:\n",
    "    if os.path.exists(results_dir + \"/\" + gene + _results.csv):\n",
    "        continue\n",
    "    merge_gene_data_and_coords(data_dir_test,patient, results_dir, gene + \"_results.csv\", gene)\n",
    "    \n",
    "for patient in patients_train:\n",
    "    if os.path.exists(results_dir + \"/\" + gene + _results.csv):\n",
    "        continue\n",
    "    merge_gene_data_and_coords(data_dir_train,patient, results_dir, gene + \"_results.csv\", gene)\n",
    "\"\"\""
   ],
   "id": "234afb5d33a57c1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T11:04:17.086829Z",
     "start_time": "2024-08-12T11:04:17.086604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_results2(model, model_path, device, data_dir, results_dir, patient=None, gene=\"RUBCNL\", results_filename=None):#\n",
    "    if results_filename is None:\n",
    "        results_filename = gene + \"_results.csv\"\n",
    "    model.eval()\n",
    "    loader = get_patient_loader(data_dir, patient, gene)\n",
    "    filename = results_dir + \"/\" + patient + \"/\" + results_filename\n",
    "    if os.path.exists(filename):\n",
    "        file_df = pd.read_csv(filename)\n",
    "        if model_path in file_df:\n",
    "            print(model_path + \" already calculated\")\n",
    "            return\n",
    "    else:\n",
    "        print(filename + \" does not exist\")\n",
    "        return\n",
    "\n",
    "    i = 0\n",
    "    j = len(loader)\n",
    "    with torch.no_grad():\n",
    "        for images, _, name in loader:\n",
    "            if i % 1000 == 0:\n",
    "                print(i, \"/\", j)\n",
    "            i += 1\n",
    "            images = images.unsqueeze(0).to(device)\n",
    "            images = images.float()\n",
    "\n",
    "            output = model(images)\n",
    "            output = output.squeeze().unsqueeze(0)\n",
    "            file_df.loc[file_df['tile'] == os.path.basename(name),[model_path]] = output.item()\n",
    "\n",
    "    file_df.to_csv(filename, index=False)\n",
    "\n",
    "for model in models:\n",
    "    for patient in patients_train:\n",
    "        print(model[1],patient)\n",
    "        generate_results2(model[0], model[1], device, data_dir_train, results_dir, patient)\n",
    "        \n",
    "for model in models:\n",
    "    for patient in patients_test:\n",
    "        if patient == \"p021\":\n",
    "            continue\n",
    "        print(model[1],patient)\n",
    "        generate_results2(model[0], model[1], device, data_dir_test, results_dir, patient)"
   ],
   "id": "6419d0f3f99033f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf73d2ec85456818"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "f40286b3-2199-475a-a984-beea7035303e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:43:35.312932Z",
     "start_time": "2024-07-16T12:43:33.142590Z"
    }
   },
   "source": [
    "from func import MyNet2, get_patient_loader\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import zennit as zen\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models.vgg import VGG\n",
    "from torch.nn.modules.pooling import MaxPool2d, AdaptiveAvgPool2d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.linear import Linear\n",
    "from zennit.rules import Epsilon, AlphaBeta\n",
    "from zennit.types import Linear\n",
    "from zennit.core import Composite\n",
    "from zennit.attribution import Gradient\n",
    "from torchvision.models.resnet import ResNet\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch.nn.modules.container import Sequential\n",
    "from torch.nn.modules.conv import Conv2d\n",
    "import os\n",
    "from restructure import *\n",
    "\n",
    "\"\"\"\n",
    "different components to the other model\n",
    "<class 'func.MyNet'>\n",
    "<class 'torchvision.models.resnet.ResNet'>\n",
    "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
    "<class 'torchvision.models.resnet.Bottleneck'>\n",
    "<class 'torch.nn.modules.batchnorm.BatchNorm1d'>\n",
    "\"\"\"\n",
    "\n",
    "# TODO: BatchNorm2d, Bottleneck, BatchNorm1d"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4002c006-1172-46f4-8006-9fd200980023",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-16T16:01:11.300694Z",
     "start_time": "2024-07-16T16:01:10.568941Z"
    }
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def get_res18(path):\n",
    "    class Res18(nn.Module):\n",
    "        def __init__(self, ciga):\n",
    "            super(Res18, self).__init__()\n",
    "            self.pretrained = ciga\n",
    "\n",
    "            self.gene1 = nn.Sequential(nn.Linear(512, 200), nn.ReLU(), nn.Linear(200, 1))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pretrained(x)\n",
    "            x = self.gene1(x)\n",
    "            return x\n",
    "\n",
    "    ciga = models.resnet18()\n",
    "    ciga.fc = torch.nn.Sequential()\n",
    "    res18 = Res18(ciga)\n",
    "    print(res18.load_state_dict(torch.load(path, map_location=torch.device('cpu'))))\n",
    "    return(res18)\n",
    "\n",
    "path = \"../models/res18/res18_not_iced_e29.pt\"\n",
    "res18_no_ice = get_res18(path).to(device)\n",
    "path = \"../models/res18/RUBCNL_HLR_Res18_optim_ice/15072024_ep_29_lr_0.0005resnet.pt\"\n",
    "res18_ice    = get_res18(path).to(device)\n",
    "res18_ice.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "path = \"../models/res18/res18_iced_e29.pt\"\n",
    "res18    = get_res18(path).to(device)\n",
    "\n",
    "\"\"\"\n",
    "model = MyNet2(my_pretrained_model=models.resnet50(weights=\"IMAGENET1K_V2\"))\n",
    "path = \"./data/05072024_single__5e-06resnet2.pt\"\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# model as a sequential for the restructuring\n",
    "modules = []\n",
    "modules.append(res18_no_ice.pretrained)\n",
    "for layer in res18_no_ice.gene1:\n",
    "    modules.append(layer)\n",
    "\n",
    "sequential_no_ice = nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "\n",
    "modules = []\n",
    "modules.append(res18_ice.pretrained)\n",
    "for layer in res18_ice.gene1:\n",
    "    modules.append(layer)\n",
    "\n",
    "sequential_ice = nn.Sequential(*modules)\n",
    "\"\"\"\n",
    "\n",
    "data_dir = \"../Training_Data\"\n",
    "patient = \"/p009\"\n",
    "base_path = data_dir+patient+\"/Preprocessed_STDataset/\"\n",
    "merge = pd.read_csv(base_path + \"merge.csv\")\n",
    "merge.head()\n",
    "loader = get_patient_loader(data_dir, patient)\n"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0f3e6c56-fdb2-4465-8d98-d5a0e557f1c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-15T12:05:20.114062Z",
     "start_time": "2024-07-15T12:05:20.110892Z"
    }
   },
   "source": "print(sequential_ice)",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba6d9e536918de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T16:40:07.376633Z",
     "start_time": "2024-07-04T16:40:01.027029Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "model_copy = copy.deepcopy(sequential).to(\"cpu\")\n",
    "for i in range (1):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    flood = find_a_ref(model_copy.to(\"cpu\"), input.to(\"cpu\"), y_ref=target.cpu(), method='flood', step_width=0.005, max_it=10e4, normalize_top=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6db4d5fac431428e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:43:48.390133Z",
     "start_time": "2024-07-16T12:43:48.383154Z"
    }
   },
   "source": [
    "def plot_relevance(att, filename = None):\n",
    "    if filename is None:\n",
    "        rel = att.sum(1).cpu()\n",
    "    else:\n",
    "        rel = torch.tensor(plt.imread(filename)).unsqueeze(0)\n",
    "    # create an image of the visualize attribution\n",
    "    img = zen.image.imgify(rel, symmetric=True, cmap='coldnhot')\n",
    "    \n",
    "    # show the image\n",
    "    display(img)\n",
    "    return img\n",
    "    \n",
    "def get_img_target_name(loader, device, tile_no):\n",
    "    image, target, name = loader[tile_no]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    image = image.float()\n",
    "    target = torch.tensor(target[0]).to(device)\n",
    "    return image, target, name\n",
    "\n",
    "\n",
    "def get_coords_from_name(data_dir, patient, tile_name):\n",
    "    base_path = data_dir+patient+\"/Preprocessed_STDataset/\"\n",
    "    merge = pd.read_csv(base_path + \"merge.csv\")\n",
    "    line = merge.loc[merge['tile'] == tile_name]\n",
    "    x = line['x']\n",
    "    y = line['y']\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def relevance_and_plot(model, mapping_fn, composite, input = None):\n",
    "\n",
    "    #composite = Composite(module_map=mapping_fn, canonizers=[canonizer])\n",
    "    if input is None:\n",
    "        input = torch.randn(1, 3, 224, 224).to(device)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "    imshow = input.to('cpu').squeeze().numpy().sum(axis=0)\n",
    "    plt.imshow(imshow)\n",
    "    plot_relevance(grad)\n",
    "    print(\"out: \", out)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9b309ab964618f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:20:13.306880Z",
     "start_time": "2024-07-04T12:20:10.392212Z"
    },
    "tags": []
   },
   "source": [
    "for i in range(len(out_target)):\n",
    "    with open(\"./xai_log.txt\", \"a\") as f:\n",
    "        out, grad, target, name = out_target[i]\n",
    "        s = \"out: \" + str(out.item()) + \", target: \" + str(target.item()) + \", filename \" + name.replace(\"//\", \"/\") + \"\\n\"\n",
    "        f.write(s)\n",
    "        plot_relevance(grad) \n",
    "        img = plt.imread(name)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        print(s)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d0541234-e607-4c77-9949-66b2ba8fc006",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-16T16:03:02.567399Z",
     "start_time": "2024-07-16T16:03:00.936430Z"
    }
   },
   "source": [
    "from restructure import find_a_ref, restructure_model\n",
    "import copy\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[zen.torchvision.ResNetCanonizer()])\n",
    "out_target = []\n",
    "model = res18_no_ice\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    x, y = get_coords_from_name(data_dir,patient,os.path.basename(name))\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy.gene1, torch.tensor(0), in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "    out_orig = model(input)\n",
    "    \"\"\"\n",
    "    model_copy = copy.deepcopy(sequential_ice).to(\"cpu\")\n",
    "    #model_copy.to(device)\n",
    "\n",
    "    flood = find_a_ref(model_copy, input.to(\"cpu\"), y_ref=0, method='flood', step_width=0.005, max_it=10e4, normalize_top=False)\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy, flood, in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_flood0, grad_flood0 = attributor(input)\n",
    "        if grad_cpy.count_nonzero() == 0:\n",
    "            continue\n",
    "            \n",
    "    model_copy = copy.deepcopy(sequential_no_ice)\n",
    "    model_copy.to(device)\n",
    "    \n",
    "    flood = find_a_ref(model_copy, input, y_ref=target, method='flood', step_width=0.005, max_it=10e4, normalize_top=False)\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy.gene1, flood, in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_flood_tar, grad_flood_tar = attributor(input)\n",
    "        if grad_cpy.count_nonzero() == 0:\n",
    "            continue\n",
    "    \n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out_ori, grad_ori = attributor(input)\n",
    "        if grad_ori.count_nonzero() == 0:\n",
    "            continue\n",
    "    \"\"\"\n",
    "    \n",
    "    out_target.append((out, out_orig, grad, target, x, y, name))\n",
    "\n",
    "images = []\n",
    "coords = []\n",
    "for i in range(len(out_target)):\n",
    "    with open(\"./xai_log.txt\", \"a\") as f:\n",
    "        out, out_orig, grad, target, x, y, name = out_target[i]\n",
    "        s = \"out: \" + str(out.item()) + \", out_orig: \" + str(out_orig.item()) + \", target: \" + str(target.item()) + \", filename: \" + os.path.basename(name.replace(\"//\", \"/\")) + \"\\n\"\n",
    "        f.write(s)\n",
    "        #plot_relevance(grad)\n",
    "        \n",
    "        #img = plt.imread(name)\n",
    "        #images.append(img)\n",
    "        #coords.append([x-112,x+112,y-112,y+112])\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "        \n",
    "        print(s)"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:54:51.796538Z",
     "start_time": "2024-07-16T12:54:51.704506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    plt.imshow(input.to(\"cpu\").squeeze())\n",
    "    plt.show()"
   ],
   "id": "2da29b7c7aa7ad76",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for extend, img in zip(coords, images):\n",
    "    ax.imshow(img, extend=extend)"
   ],
   "id": "c20929fc2366ce6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81ba6425-713e-4f44-ac04-53db15a6afb4",
   "metadata": {},
   "source": [
    "model_copy.to(device)\n",
    "y_t_ = model_copy.forward(input)\n",
    "a_ref_ = model_copy[:-1](input)\n",
    "b_ref_ = model_copy(input)[:-1]\n",
    "c_ref_ = model_copy(input)\n",
    "\n",
    "\n",
    "\n",
    "print(a_ref_)\n",
    "print(b_ref_)\n",
    "print(c_ref_)\n",
    "print(c_ref_[:-1])\n",
    "xxx = [\"a\"]\n",
    "print(xxx[:-1] and xxx[-1])\n",
    "\n",
    "#print(y_t_.item(), \" \", a_ref_.item())\n",
    "#model_copy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5d626098ed07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:21:01.283590Z",
     "start_time": "2024-07-04T12:21:01.275835Z"
    }
   },
   "source": [
    "log = False\n",
    "def module_map_orig(ctx, name, module):\n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        return None\n",
    "\n",
    "    # count the number of the leaves processed yet in 'leafnum'\n",
    "    if 'leafnum' not in ctx:\n",
    "        ctx['leafnum'] = 0\n",
    "    else:\n",
    "        ctx['leafnum'] += 1\n",
    "\n",
    "    # the first 10 leaf-modules which are of type Linear should be assigned\n",
    "    # the Alpha2Beta1 rule\n",
    "    if ctx['leafnum'] < 10:\n",
    "        if log:\n",
    "            print(type(module), \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "        return AlphaBeta(alpha=2, beta=1)\n",
    "    if log:\n",
    "        print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "    # all other rules should be assigned Epsilon\n",
    "    return Epsilon(epsilon=1e-3)\n",
    "\n",
    "\n",
    "def module_map_debug(ctx, name, module):\n",
    "    if type(module) is MyNet:             return None\n",
    "    if type(module) is ResNet:            return None\n",
    "    if type(module) is ReLU:              return None\n",
    "    if type(module) is Sequential:        return None\n",
    "    if type(module) is VGG:               return None\n",
    "    if type(module) is MaxPool2d:         return None\n",
    "    if type(module) is Dropout:           return None\n",
    "    if type(module) is AdaptiveAvgPool2d: return None\n",
    "    \n",
    "    if type(module) is Conv2d:            return Epsilon(epsilon=1e-3)\n",
    "    if type(module) is Linear:\n",
    "        # count the number of the leaves processed yet in 'leafnum'\n",
    "        if 'leafnum' not in ctx:\n",
    "            ctx['leafnum'] = 0\n",
    "        else:\n",
    "            ctx['leafnum'] += 1\n",
    "        if ctx['leafnum'] < 10:\n",
    "            if log:\n",
    "                print(type(module), \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "            return AlphaBeta(alpha=2, beta=1)\n",
    "        if log:\n",
    "            print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "        return Epsilon(epsilon=1e-3)\n",
    "    \n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "    if log:\n",
    "        print(type(module), \" isinstance(Linear): \", isinstance(module, Linear))\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "def module_map_my_net_debug(ctx, name, module):\n",
    "    if type(module) is MyNet:      return None\n",
    "    if type(module) is ResNet:     return None\n",
    "    if type(module) is ReLU:       return None\n",
    "    if type(module) is Sequential: return None\n",
    "    \n",
    "    if type(module) is Conv2d:     return Epsilon(epsilon=1e-3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        return None\n",
    "\n",
    "    # count the number of the leaves processed yet in 'leafnum'\n",
    "    if 'leafnum' not in ctx:\n",
    "        ctx['leafnum'] = 0\n",
    "    else:\n",
    "        ctx['leafnum'] += 1\n",
    "\n",
    "    # the first 10 leaf-modules which are of type Linear should be assigned\n",
    "    # the Alpha2Beta1 rule\n",
    "    if ctx['leafnum'] < 10:\n",
    "        if log:\n",
    "            print(\"leafnum \", ctx['leafnum'], type(module) , \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "        return AlphaBeta(alpha=2, beta=1)\n",
    "    if log:\n",
    "        print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "    # all other rules should be assigned Epsilon\n",
    "    return Epsilon(epsilon=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291426a156f5df53",
   "metadata": {},
   "source": [
    "print(grad.shape)\n",
    "print(grad.squeeze().shape)\n",
    "r = plt.imread(filename)\n",
    "print(r.shape)\n",
    "plot_relevance(None, filename)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164ed632cbccc84",
   "metadata": {},
   "source": [
    "for i in range (len(out_target)):\n",
    "    out, grad, target, name = out_target[i]\n",
    "    print(target)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde235f704575e0",
   "metadata": {},
   "source": [
    "out, grad, target, name = out_target[1]\n",
    "print(name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd0c4ddfa2dfa",
   "metadata": {},
   "source": [
    "class ResNetCanonizer(zen.torchvision.CompositeCanonizer):\n",
    "    '''Canonizer for torchvision.models.resnet* type models. This applies SequentialMergeBatchNorm, as well as\n",
    "    add a Sum module to the Bottleneck modules and overload their forward method to use the Sum module instead of\n",
    "    simply adding two tensors, such that forward and backward hooks may be applied.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__((\n",
    "            zen.torchvision.SequentialMergeBatchNorm(),\n",
    "            zen.torchvision.ResNetBottleneckCanonizer(),\n",
    "            zen.torchvision.ResNetBasicBlockCanonizer(),\n",
    "        ))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab2e9805e3c790",
   "metadata": {},
   "source": [
    "newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model_drop = models.resnet50(pretrained=True)\n",
    "print(newmodel)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2926ba9d53d64a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:06:24.232178Z",
     "start_time": "2024-07-15T12:06:19.796859Z"
    }
   },
   "source": [
    "vgg = models.vgg16()\n",
    "res = models.resnet50()\n",
    "current_model = res18_ice\n",
    "img, target, filename = get_img_target_name(loader, device, 2)\n",
    "\n",
    "can_res = zen.torchvision.ResNetCanonizer()\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[can_res])\n",
    "\n",
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(current_model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))\n",
    "\n",
    "\n",
    "#relevance_and_plot(current_model.to(device), module_map_debug, composite, img)\n",
    "#print(\"target: \", target)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7d28b7-7d70-46ba-84f6-f166522b3dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:20:10.390485Z",
     "start_time": "2024-07-04T12:20:03.034437Z"
    }
   },
   "source": [
    "vgg = models.vgg16()\n",
    "res = models.resnet50()\n",
    "current_model = res18_ice\n",
    "img, target, filename = get_img_target_name(loader, device, 2)\n",
    "\n",
    "can_res = zen.torchvision.ResNetCanonizer()\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[can_res])\n",
    "\n",
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))\n",
    "\n",
    "\n",
    "#relevance_and_plot(current_model.to(device), module_map_debug, composite, img)\n",
    "#print(\"target: \", target)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2443ce42-31ca-4589-8713-721705e3a9b8",
   "metadata": {},
   "source": [
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(sequential, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f8db01c046bfc",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd58e78402a494f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174457c6d87dd1c",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

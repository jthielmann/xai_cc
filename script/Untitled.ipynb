{
 "cells": [
  {
   "cell_type": "code",
   "id": "f40286b3-2199-475a-a984-beea7035303e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:43:35.312932Z",
     "start_time": "2024-07-16T12:43:33.142590Z"
    }
   },
   "source": [
    "from func import MyNet2, get_patient_loader\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import zennit as zen\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models.vgg import VGG\n",
    "from torch.nn.modules.pooling import MaxPool2d, AdaptiveAvgPool2d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.linear import Linear\n",
    "from zennit.rules import Epsilon, AlphaBeta\n",
    "from zennit.types import Linear\n",
    "from zennit.core import Composite\n",
    "from zennit.attribution import Gradient\n",
    "from torchvision.models.resnet import ResNet\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch.nn.modules.container import Sequential\n",
    "from torch.nn.modules.conv import Conv2d\n",
    "import os\n",
    "from restructure import *\n",
    "\n",
    "\"\"\"\n",
    "different components to the other model\n",
    "<class 'func.MyNet'>\n",
    "<class 'torchvision.models.resnet.ResNet'>\n",
    "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
    "<class 'torchvision.models.resnet.Bottleneck'>\n",
    "<class 'torch.nn.modules.batchnorm.BatchNorm1d'>\n",
    "\"\"\"\n",
    "\n",
    "# TODO: BatchNorm2d, Bottleneck, BatchNorm1d"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <D9493EF5-8DAB-3A5D-85D5-684F04544B84> /Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7856C0E5-3D52-39C7-8515-71217150BD2E> /Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndifferent components to the other model\\n<class 'func.MyNet'>\\n<class 'torchvision.models.resnet.ResNet'>\\n<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\\n<class 'torchvision.models.resnet.Bottleneck'>\\n<class 'torch.nn.modules.batchnorm.BatchNorm1d'>\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4002c006-1172-46f4-8006-9fd200980023",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-16T16:01:11.300694Z",
     "start_time": "2024-07-16T16:01:10.568941Z"
    }
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def get_res18(path):\n",
    "    class Res18(nn.Module):\n",
    "        def __init__(self, ciga):\n",
    "            super(Res18, self).__init__()\n",
    "            self.pretrained = ciga\n",
    "\n",
    "            self.gene1 = nn.Sequential(nn.Linear(512, 200), nn.ReLU(), nn.Linear(200, 1))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pretrained(x)\n",
    "            x = self.gene1(x)\n",
    "            return x\n",
    "\n",
    "    ciga = models.resnet18()\n",
    "    ciga.fc = torch.nn.Sequential()\n",
    "    res18 = Res18(ciga)\n",
    "    print(res18.load_state_dict(torch.load(path, map_location=torch.device('cpu'))))\n",
    "    return(res18)\n",
    "\n",
    "path = \"../models/res18/res18_not_iced_e29.pt\"\n",
    "res18_no_ice = get_res18(path).to(device)\n",
    "path = \"../models/res18/RUBCNL_HLR_Res18_optim_ice/15072024_ep_29_lr_0.0005resnet.pt\"\n",
    "res18_ice    = get_res18(path).to(device)\n",
    "res18_ice.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "path = \"../models/res18/res18_iced_e29.pt\"\n",
    "res18    = get_res18(path).to(device)\n",
    "\n",
    "\"\"\"\n",
    "model = MyNet2(my_pretrained_model=models.resnet50(weights=\"IMAGENET1K_V2\"))\n",
    "path = \"./data/05072024_single__5e-06resnet2.pt\"\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# model as a sequential for the restructuring\n",
    "modules = []\n",
    "modules.append(res18_no_ice.pretrained)\n",
    "for layer in res18_no_ice.gene1:\n",
    "    modules.append(layer)\n",
    "\n",
    "sequential_no_ice = nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "\n",
    "modules = []\n",
    "modules.append(res18_ice.pretrained)\n",
    "for layer in res18_ice.gene1:\n",
    "    modules.append(layer)\n",
    "\n",
    "sequential_ice = nn.Sequential(*modules)\n",
    "\"\"\"\n",
    "\n",
    "data_dir = \"../Training_Data\"\n",
    "patient = \"/p009\"\n",
    "base_path = data_dir+patient+\"/Preprocessed_STDataset/\"\n",
    "merge = pd.read_csv(base_path + \"merge.csv\")\n",
    "merge.head()\n",
    "loader = get_patient_loader(data_dir, patient)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "0f3e6c56-fdb2-4465-8d98-d5a0e557f1c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-15T12:05:20.114062Z",
     "start_time": "2024-07-15T12:05:20.110892Z"
    }
   },
   "source": "print(sequential_ice)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential()\n",
      "  )\n",
      "  (1): Linear(in_features=512, out_features=200, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba6d9e536918de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T16:40:07.376633Z",
     "start_time": "2024-07-04T16:40:01.027029Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "model_copy = copy.deepcopy(sequential).to(\"cpu\")\n",
    "for i in range (1):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    flood = find_a_ref(model_copy.to(\"cpu\"), input.to(\"cpu\"), y_ref=target.cpu(), method='flood', step_width=0.005, max_it=10e4, normalize_top=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6db4d5fac431428e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:43:48.390133Z",
     "start_time": "2024-07-16T12:43:48.383154Z"
    }
   },
   "source": [
    "def plot_relevance(att, filename = None):\n",
    "    if filename is None:\n",
    "        rel = att.sum(1).cpu()\n",
    "    else:\n",
    "        rel = torch.tensor(plt.imread(filename)).unsqueeze(0)\n",
    "    # create an image of the visualize attribution\n",
    "    img = zen.image.imgify(rel, symmetric=True, cmap='coldnhot')\n",
    "    \n",
    "    # show the image\n",
    "    display(img)\n",
    "    return img\n",
    "    \n",
    "def get_img_target_name(loader, device, tile_no):\n",
    "    image, target, name = loader[tile_no]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    image = image.float()\n",
    "    target = torch.tensor(target[0]).to(device)\n",
    "    return image, target, name\n",
    "\n",
    "\n",
    "def get_coords_from_name(data_dir, patient, tile_name):\n",
    "    base_path = data_dir+patient+\"/Preprocessed_STDataset/\"\n",
    "    merge = pd.read_csv(base_path + \"merge.csv\")\n",
    "    line = merge.loc[merge['tile'] == tile_name]\n",
    "    x = line['x']\n",
    "    y = line['y']\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def relevance_and_plot(model, mapping_fn, composite, input = None):\n",
    "\n",
    "    #composite = Composite(module_map=mapping_fn, canonizers=[canonizer])\n",
    "    if input is None:\n",
    "        input = torch.randn(1, 3, 224, 224).to(device)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "    imshow = input.to('cpu').squeeze().numpy().sum(axis=0)\n",
    "    plt.imshow(imshow)\n",
    "    plot_relevance(grad)\n",
    "    print(\"out: \", out)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9b309ab964618f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:20:13.306880Z",
     "start_time": "2024-07-04T12:20:10.392212Z"
    },
    "tags": []
   },
   "source": [
    "for i in range(len(out_target)):\n",
    "    with open(\"./xai_log.txt\", \"a\") as f:\n",
    "        out, grad, target, name = out_target[i]\n",
    "        s = \"out: \" + str(out.item()) + \", target: \" + str(target.item()) + \", filename \" + name.replace(\"//\", \"/\") + \"\\n\"\n",
    "        f.write(s)\n",
    "        plot_relevance(grad) \n",
    "        img = plt.imread(name)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        print(s)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d0541234-e607-4c77-9949-66b2ba8fc006",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-16T16:03:02.567399Z",
     "start_time": "2024-07-16T16:03:00.936430Z"
    }
   },
   "source": [
    "from restructure import find_a_ref, restructure_model\n",
    "import copy\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[zen.torchvision.ResNetCanonizer()])\n",
    "out_target = []\n",
    "model = res18_no_ice\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    x, y = get_coords_from_name(data_dir,patient,os.path.basename(name))\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy.gene1, torch.tensor(0), in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "    out_orig = model(input)\n",
    "    \"\"\"\n",
    "    model_copy = copy.deepcopy(sequential_ice).to(\"cpu\")\n",
    "    #model_copy.to(device)\n",
    "\n",
    "    flood = find_a_ref(model_copy, input.to(\"cpu\"), y_ref=0, method='flood', step_width=0.005, max_it=10e4, normalize_top=False)\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy, flood, in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_flood0, grad_flood0 = attributor(input)\n",
    "        if grad_cpy.count_nonzero() == 0:\n",
    "            continue\n",
    "            \n",
    "    model_copy = copy.deepcopy(sequential_no_ice)\n",
    "    model_copy.to(device)\n",
    "    \n",
    "    flood = find_a_ref(model_copy, input, y_ref=target, method='flood', step_width=0.005, max_it=10e4, normalize_top=False)\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy.gene1, flood, in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_flood_tar, grad_flood_tar = attributor(input)\n",
    "        if grad_cpy.count_nonzero() == 0:\n",
    "            continue\n",
    "    \n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out_ori, grad_ori = attributor(input)\n",
    "        if grad_ori.count_nonzero() == 0:\n",
    "            continue\n",
    "    \"\"\"\n",
    "    \n",
    "    out_target.append((out, out_orig, grad, target, x, y, name))\n",
    "\n",
    "images = []\n",
    "coords = []\n",
    "for i in range(len(out_target)):\n",
    "    with open(\"./xai_log.txt\", \"a\") as f:\n",
    "        out, out_orig, grad, target, x, y, name = out_target[i]\n",
    "        s = \"out: \" + str(out.item()) + \", out_orig: \" + str(out_orig.item()) + \", target: \" + str(target.item()) + \", filename: \" + os.path.basename(name.replace(\"//\", \"/\")) + \"\\n\"\n",
    "        f.write(s)\n",
    "        #plot_relevance(grad)\n",
    "        \n",
    "        #img = plt.imread(name)\n",
    "        #images.append(img)\n",
    "        #coords.append([x-112,x+112,y-112,y+112])\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "        \n",
    "        print(s)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: -0.12255256623029709, out_orig: -0.07183544337749481, target: -0.1566115766763687, filename: p009_72_0.tiff\n",
      "\n",
      "out: -0.0009207874536514282, out_orig: -0.06663620471954346, target: -0.33355867862701416, filename: p009_73_0.tiff\n",
      "\n",
      "out: -0.025556311011314392, out_orig: -0.06566643714904785, target: -7.824455678928643e-05, filename: p009_74_0.tiff\n",
      "\n",
      "out: -0.014656178653240204, out_orig: -0.02692045271396637, target: -0.7764939665794373, filename: p009_75_0.tiff\n",
      "\n",
      "out: -0.06791572272777557, out_orig: -0.040368545800447464, target: 0.14026819169521332, filename: p009_76_0.tiff\n",
      "\n",
      "out: -0.08436466753482819, out_orig: -0.07824289798736572, target: -7.824455678928643e-05, filename: p009_77_0.tiff\n",
      "\n",
      "out: -0.054173171520233154, out_orig: -0.06115890294313431, target: 0.26746365427970886, filename: p009_78_0.tiff\n",
      "\n",
      "out: -0.012269746512174606, out_orig: -0.04143543541431427, target: 0.14026819169521332, filename: p009_79_0.tiff\n",
      "\n",
      "out: -0.09131471067667007, out_orig: -0.04913434013724327, target: -0.5370539426803589, filename: p009_80_0.tiff\n",
      "\n",
      "out: -0.08062005788087845, out_orig: -0.053836889564991, target: -0.7764939665794373, filename: p009_81_0.tiff\n",
      "\n",
      "out: -0.01823968067765236, out_orig: -0.09067817032337189, target: 0.3837631046772003, filename: p009_82_0.tiff\n",
      "\n",
      "out: -0.039725665003061295, out_orig: 0.004877500236034393, target: -7.824455678928643e-05, filename: p009_83_0.tiff\n",
      "\n",
      "out: -0.01386510580778122, out_orig: -0.06252579391002655, target: -1.0673601627349854, filename: p009_84_0.tiff\n",
      "\n",
      "out: -0.005437824875116348, out_orig: -0.03574284911155701, target: 0.4908868074417114, filename: p009_85_0.tiff\n",
      "\n",
      "out: -0.05520634353160858, out_orig: -0.06220090016722679, target: 0.7693269848823547, filename: p009_86_0.tiff\n",
      "\n",
      "out: 0.051676370203495026, out_orig: -0.014460969716310501, target: 0.26746365427970886, filename: p009_87_0.tiff\n",
      "\n",
      "out: -0.019442088901996613, out_orig: -0.06836706399917603, target: 0.26746365427970886, filename: p009_88_0.tiff\n",
      "\n",
      "out: -0.022692639380693436, out_orig: -0.02861759066581726, target: 0.4908868074417114, filename: p009_89_0.tiff\n",
      "\n",
      "out: 0.07973308116197586, out_orig: -0.03353257104754448, target: -1.0673601627349854, filename: p009_69_1.tiff\n",
      "\n",
      "out: -0.0758957490324974, out_orig: -0.040553972125053406, target: -0.33355867862701416, filename: p009_70_1.tiff\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T12:54:51.796538Z",
     "start_time": "2024-07-16T12:54:51.704506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    plt.imshow(input.to(\"cpu\").squeeze())\n",
    "    plt.show()"
   ],
   "id": "2da29b7c7aa7ad76",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 224, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [13], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m20\u001B[39m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28minput\u001B[39m, target, name \u001B[38;5;241m=\u001B[39m get_img_target_name(loader,device,i)\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:454\u001B[0m, in \u001B[0;36mmake_keyword_only.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m name_idx:\n\u001B[1;32m    449\u001B[0m     warn_deprecated(\n\u001B[1;32m    450\u001B[0m         since, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing the \u001B[39m\u001B[38;5;132;01m%(name)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%(obj_type)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    451\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositionally is deprecated since Matplotlib \u001B[39m\u001B[38;5;132;01m%(since)s\u001B[39;00m\u001B[38;5;124m; the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    452\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter will become keyword-only \u001B[39m\u001B[38;5;132;01m%(removal)s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    453\u001B[0m         name\u001B[38;5;241m=\u001B[39mname, obj_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/matplotlib/pyplot.py:2623\u001B[0m, in \u001B[0;36mimshow\u001B[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[1;32m   2617\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[1;32m   2618\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[1;32m   2619\u001B[0m         X, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, aspect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, interpolation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   2620\u001B[0m         alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, extent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   2621\u001B[0m         interpolation_stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, filternorm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, filterrad\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4.0\u001B[39m,\n\u001B[1;32m   2622\u001B[0m         resample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m-> 2623\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2624\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maspect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maspect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2625\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2626\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2627\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation_stage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2628\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilternorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilternorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilterrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilterrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2629\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2630\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2631\u001B[0m     sci(__ret)\n\u001B[1;32m   2632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:454\u001B[0m, in \u001B[0;36mmake_keyword_only.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m name_idx:\n\u001B[1;32m    449\u001B[0m     warn_deprecated(\n\u001B[1;32m    450\u001B[0m         since, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing the \u001B[39m\u001B[38;5;132;01m%(name)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%(obj_type)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    451\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositionally is deprecated since Matplotlib \u001B[39m\u001B[38;5;132;01m%(since)s\u001B[39;00m\u001B[38;5;124m; the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    452\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter will become keyword-only \u001B[39m\u001B[38;5;132;01m%(removal)s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    453\u001B[0m         name\u001B[38;5;241m=\u001B[39mname, obj_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/matplotlib/__init__.py:1423\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1420\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m   1421\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1422\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1423\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1425\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1426\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[1;32m   1427\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5604\u001B[0m, in \u001B[0;36mAxes.imshow\u001B[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[0m\n\u001B[1;32m   5596\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_aspect(aspect)\n\u001B[1;32m   5597\u001B[0m im \u001B[38;5;241m=\u001B[39m mimage\u001B[38;5;241m.\u001B[39mAxesImage(\u001B[38;5;28mself\u001B[39m, cmap\u001B[38;5;241m=\u001B[39mcmap, norm\u001B[38;5;241m=\u001B[39mnorm,\n\u001B[1;32m   5598\u001B[0m                       interpolation\u001B[38;5;241m=\u001B[39minterpolation, origin\u001B[38;5;241m=\u001B[39morigin,\n\u001B[1;32m   5599\u001B[0m                       extent\u001B[38;5;241m=\u001B[39mextent, filternorm\u001B[38;5;241m=\u001B[39mfilternorm,\n\u001B[1;32m   5600\u001B[0m                       filterrad\u001B[38;5;241m=\u001B[39mfilterrad, resample\u001B[38;5;241m=\u001B[39mresample,\n\u001B[1;32m   5601\u001B[0m                       interpolation_stage\u001B[38;5;241m=\u001B[39minterpolation_stage,\n\u001B[1;32m   5602\u001B[0m                       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 5604\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5605\u001B[0m im\u001B[38;5;241m.\u001B[39mset_alpha(alpha)\n\u001B[1;32m   5606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5607\u001B[0m     \u001B[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/matplotlib/image.py:710\u001B[0m, in \u001B[0;36m_ImageBase.set_data\u001B[0;34m(self, A)\u001B[0m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A[:, :, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    708\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    709\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m]):\n\u001B[0;32m--> 710\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid shape \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m for image data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    711\u001B[0m                     \u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape))\n\u001B[1;32m    713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m    714\u001B[0m     \u001B[38;5;66;03m# If the input data has values outside the valid range (after\u001B[39;00m\n\u001B[1;32m    715\u001B[0m     \u001B[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001B[39;00m\n\u001B[1;32m    716\u001B[0m     \u001B[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001B[39;00m\n\u001B[1;32m    717\u001B[0m     \u001B[38;5;66;03m# making reliable interpretation impossible.\u001B[39;00m\n\u001B[1;32m    718\u001B[0m     high \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39minteger) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: Invalid shape (3, 224, 224) for image data"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for extend, img in zip(coords, images):\n",
    "    ax.imshow(img, extend=extend)"
   ],
   "id": "c20929fc2366ce6"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81ba6425-713e-4f44-ac04-53db15a6afb4",
   "metadata": {},
   "source": [
    "model_copy.to(device)\n",
    "y_t_ = model_copy.forward(input)\n",
    "a_ref_ = model_copy[:-1](input)\n",
    "b_ref_ = model_copy(input)[:-1]\n",
    "c_ref_ = model_copy(input)\n",
    "\n",
    "\n",
    "\n",
    "print(a_ref_)\n",
    "print(b_ref_)\n",
    "print(c_ref_)\n",
    "print(c_ref_[:-1])\n",
    "xxx = [\"a\"]\n",
    "print(xxx[:-1] and xxx[-1])\n",
    "\n",
    "#print(y_t_.item(), \" \", a_ref_.item())\n",
    "#model_copy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5d626098ed07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:21:01.283590Z",
     "start_time": "2024-07-04T12:21:01.275835Z"
    }
   },
   "source": [
    "log = False\n",
    "def module_map_orig(ctx, name, module):\n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        return None\n",
    "\n",
    "    # count the number of the leaves processed yet in 'leafnum'\n",
    "    if 'leafnum' not in ctx:\n",
    "        ctx['leafnum'] = 0\n",
    "    else:\n",
    "        ctx['leafnum'] += 1\n",
    "\n",
    "    # the first 10 leaf-modules which are of type Linear should be assigned\n",
    "    # the Alpha2Beta1 rule\n",
    "    if ctx['leafnum'] < 10:\n",
    "        if log:\n",
    "            print(type(module), \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "        return AlphaBeta(alpha=2, beta=1)\n",
    "    if log:\n",
    "        print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "    # all other rules should be assigned Epsilon\n",
    "    return Epsilon(epsilon=1e-3)\n",
    "\n",
    "\n",
    "def module_map_debug(ctx, name, module):\n",
    "    if type(module) is MyNet:             return None\n",
    "    if type(module) is ResNet:            return None\n",
    "    if type(module) is ReLU:              return None\n",
    "    if type(module) is Sequential:        return None\n",
    "    if type(module) is VGG:               return None\n",
    "    if type(module) is MaxPool2d:         return None\n",
    "    if type(module) is Dropout:           return None\n",
    "    if type(module) is AdaptiveAvgPool2d: return None\n",
    "    \n",
    "    if type(module) is Conv2d:            return Epsilon(epsilon=1e-3)\n",
    "    if type(module) is Linear:\n",
    "        # count the number of the leaves processed yet in 'leafnum'\n",
    "        if 'leafnum' not in ctx:\n",
    "            ctx['leafnum'] = 0\n",
    "        else:\n",
    "            ctx['leafnum'] += 1\n",
    "        if ctx['leafnum'] < 10:\n",
    "            if log:\n",
    "                print(type(module), \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "            return AlphaBeta(alpha=2, beta=1)\n",
    "        if log:\n",
    "            print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "        return Epsilon(epsilon=1e-3)\n",
    "    \n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "    if log:\n",
    "        print(type(module), \" isinstance(Linear): \", isinstance(module, Linear))\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "def module_map_my_net_debug(ctx, name, module):\n",
    "    if type(module) is MyNet:      return None\n",
    "    if type(module) is ResNet:     return None\n",
    "    if type(module) is ReLU:       return None\n",
    "    if type(module) is Sequential: return None\n",
    "    \n",
    "    if type(module) is Conv2d:     return Epsilon(epsilon=1e-3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        return None\n",
    "\n",
    "    # count the number of the leaves processed yet in 'leafnum'\n",
    "    if 'leafnum' not in ctx:\n",
    "        ctx['leafnum'] = 0\n",
    "    else:\n",
    "        ctx['leafnum'] += 1\n",
    "\n",
    "    # the first 10 leaf-modules which are of type Linear should be assigned\n",
    "    # the Alpha2Beta1 rule\n",
    "    if ctx['leafnum'] < 10:\n",
    "        if log:\n",
    "            print(\"leafnum \", ctx['leafnum'], type(module) , \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "        return AlphaBeta(alpha=2, beta=1)\n",
    "    if log:\n",
    "        print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "    # all other rules should be assigned Epsilon\n",
    "    return Epsilon(epsilon=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291426a156f5df53",
   "metadata": {},
   "source": [
    "print(grad.shape)\n",
    "print(grad.squeeze().shape)\n",
    "r = plt.imread(filename)\n",
    "print(r.shape)\n",
    "plot_relevance(None, filename)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164ed632cbccc84",
   "metadata": {},
   "source": [
    "for i in range (len(out_target)):\n",
    "    out, grad, target, name = out_target[i]\n",
    "    print(target)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde235f704575e0",
   "metadata": {},
   "source": [
    "out, grad, target, name = out_target[1]\n",
    "print(name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd0c4ddfa2dfa",
   "metadata": {},
   "source": [
    "class ResNetCanonizer(zen.torchvision.CompositeCanonizer):\n",
    "    '''Canonizer for torchvision.models.resnet* type models. This applies SequentialMergeBatchNorm, as well as\n",
    "    add a Sum module to the Bottleneck modules and overload their forward method to use the Sum module instead of\n",
    "    simply adding two tensors, such that forward and backward hooks may be applied.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__((\n",
    "            zen.torchvision.SequentialMergeBatchNorm(),\n",
    "            zen.torchvision.ResNetBottleneckCanonizer(),\n",
    "            zen.torchvision.ResNetBasicBlockCanonizer(),\n",
    "        ))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab2e9805e3c790",
   "metadata": {},
   "source": [
    "newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model_drop = models.resnet50(pretrained=True)\n",
    "print(newmodel)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2926ba9d53d64a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:06:24.232178Z",
     "start_time": "2024-07-15T12:06:19.796859Z"
    }
   },
   "source": [
    "vgg = models.vgg16()\n",
    "res = models.resnet50()\n",
    "current_model = res18_ice\n",
    "img, target, filename = get_img_target_name(loader, device, 2)\n",
    "\n",
    "can_res = zen.torchvision.ResNetCanonizer()\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[can_res])\n",
    "\n",
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(current_model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))\n",
    "\n",
    "\n",
    "#relevance_and_plot(current_model.to(device), module_map_debug, composite, img)\n",
    "#print(\"target: \", target)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7d28b7-7d70-46ba-84f6-f166522b3dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:20:10.390485Z",
     "start_time": "2024-07-04T12:20:03.034437Z"
    }
   },
   "source": [
    "vgg = models.vgg16()\n",
    "res = models.resnet50()\n",
    "current_model = res18_ice\n",
    "img, target, filename = get_img_target_name(loader, device, 2)\n",
    "\n",
    "can_res = zen.torchvision.ResNetCanonizer()\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[can_res])\n",
    "\n",
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))\n",
    "\n",
    "\n",
    "#relevance_and_plot(current_model.to(device), module_map_debug, composite, img)\n",
    "#print(\"target: \", target)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2443ce42-31ca-4589-8713-721705e3a9b8",
   "metadata": {},
   "source": [
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(sequential, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f8db01c046bfc",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd58e78402a494f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174457c6d87dd1c",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "f40286b3-2199-475a-a984-beea7035303e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:38:14.288818Z",
     "start_time": "2024-07-15T12:38:12.177710Z"
    }
   },
   "source": [
    "from func import MyNet2, get_patient_loader\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import zennit as zen\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models.vgg import VGG\n",
    "from torch.nn.modules.pooling import MaxPool2d, AdaptiveAvgPool2d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.linear import Linear\n",
    "from zennit.rules import Epsilon, AlphaBeta\n",
    "from zennit.types import Linear\n",
    "from zennit.core import Composite\n",
    "from zennit.attribution import Gradient\n",
    "from torchvision.models.resnet import ResNet\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch.nn.modules.container import Sequential\n",
    "from torch.nn.modules.conv import Conv2d\n",
    "import os\n",
    "from restructure import *\n",
    "\n",
    "\"\"\"\n",
    "different components to the other model\n",
    "<class 'func.MyNet'>\n",
    "<class 'torchvision.models.resnet.ResNet'>\n",
    "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
    "<class 'torchvision.models.resnet.Bottleneck'>\n",
    "<class 'torch.nn.modules.batchnorm.BatchNorm1d'>\n",
    "\"\"\"\n",
    "\n",
    "# TODO: BatchNorm2d, Bottleneck, BatchNorm1d"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <D9493EF5-8DAB-3A5D-85D5-684F04544B84> /Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7856C0E5-3D52-39C7-8515-71217150BD2E> /Users/jona/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndifferent components to the other model\\n<class 'func.MyNet'>\\n<class 'torchvision.models.resnet.ResNet'>\\n<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\\n<class 'torchvision.models.resnet.Bottleneck'>\\n<class 'torch.nn.modules.batchnorm.BatchNorm1d'>\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4002c006-1172-46f4-8006-9fd200980023",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-15T12:38:15.797840Z",
     "start_time": "2024-07-15T12:38:15.275618Z"
    }
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def get_res18(path):\n",
    "    class Res18(nn.Module):\n",
    "        def __init__(self, ciga):\n",
    "            super(Res18, self).__init__()\n",
    "            self.pretrained = ciga\n",
    "\n",
    "            self.gene1 = nn.Sequential(nn.Linear(512, 200), nn.ReLU(), nn.Linear(200, 1))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pretrained(x)\n",
    "            x = self.gene1(x)\n",
    "            return x\n",
    "\n",
    "    ciga = models.resnet18()\n",
    "    ciga.fc = torch.nn.Sequential()\n",
    "    res18 = Res18(ciga)\n",
    "    res18.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    return(res18)\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "path = \"../models/res18/res18_not_iced_e29.pt\"\n",
    "res18_no_ice = get_res18(path).to(device)\n",
    "path = \"../models/res18/res18_iced_e29.pt\"\n",
    "res18_ice    = get_res18(path).to(device)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model = MyNet2(my_pretrained_model=models.resnet50(weights=\"IMAGENET1K_V2\"))\n",
    "path = \"./data/05072024_single__5e-06resnet2.pt\"\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\"\"\"\n",
    "# model as a sequential for the restructuring\n",
    "modules = []\n",
    "modules.append(res18_no_ice.pretrained)\n",
    "for layer in res18_no_ice.gene1:\n",
    "    modules.append(layer)\n",
    "\n",
    "sequential_no_ice = nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "\n",
    "modules = []\n",
    "modules.append(res18_ice.pretrained)\n",
    "for layer in res18_ice.gene1:\n",
    "    modules.append(layer)\n",
    "\n",
    "sequential_ice = nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "data_dir = \"../Training_Data\"\n",
    "patient = \"/p007\"\n",
    "base_path = data_dir+patient+\"/Preprocessed_STDataset/\"\n",
    "merge = pd.read_csv(base_path + \"merge.csv\")\n",
    "merge.head()\n",
    "loader = get_patient_loader(data_dir, patient)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jona/Documents/uni/Master/master thesis/sync/xai_cc/script\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0f3e6c56-fdb2-4465-8d98-d5a0e557f1c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-15T12:05:20.114062Z",
     "start_time": "2024-07-15T12:05:20.110892Z"
    }
   },
   "source": "print(sequential_ice)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential()\n",
      "  )\n",
      "  (1): Linear(in_features=512, out_features=200, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba6d9e536918de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T16:40:07.376633Z",
     "start_time": "2024-07-04T16:40:01.027029Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "model_copy = copy.deepcopy(sequential).to(\"cpu\")\n",
    "for i in range (1):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    flood = find_a_ref(model_copy.to(\"cpu\"), input.to(\"cpu\"), y_ref=target.cpu(), method='flood', step_width=0.005, max_it=10e4, normalize_top=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6db4d5fac431428e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:38:20.028912Z",
     "start_time": "2024-07-15T12:38:20.022852Z"
    }
   },
   "source": [
    "def plot_relevance(att, filename = None):\n",
    "    if filename is None:\n",
    "        rel = att.sum(1).cpu()\n",
    "    else:\n",
    "        rel = torch.tensor(plt.imread(filename)).unsqueeze(0)\n",
    "    # create an image of the visualize attribution\n",
    "    img = zen.image.imgify(rel, symmetric=True, cmap='coldnhot')\n",
    "    \n",
    "    # show the image\n",
    "    display(img)\n",
    "    return img\n",
    "    \n",
    "def get_img_target_name(loader, device, tile_no):\n",
    "    image, target, name = loader[tile_no]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    image = image.float()\n",
    "    target = torch.tensor(target[0]).to(device)\n",
    "    return image, target, name\n",
    "\n",
    "\n",
    "def get_coords_from_name(data_dir, patient, tile_name):\n",
    "    base_path = data_dir+patient+\"/Preprocessed_STDataset/\"\n",
    "    merge = pd.read_csv(base_path + \"merge.csv\")\n",
    "    line = merge.loc[merge['tile'] == tile_name]\n",
    "    x = line['x']\n",
    "    y = line['y']\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def relevance_and_plot(model, mapping_fn, composite, input = None):\n",
    "\n",
    "    #composite = Composite(module_map=mapping_fn, canonizers=[canonizer])\n",
    "    if input is None:\n",
    "        input = torch.randn(1, 3, 224, 224).to(device)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "    imshow = input.to('cpu').squeeze().numpy().sum(axis=0)\n",
    "    plt.imshow(imshow)\n",
    "    plot_relevance(grad)\n",
    "    print(\"out: \", out)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9b309ab964618f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:20:13.306880Z",
     "start_time": "2024-07-04T12:20:10.392212Z"
    },
    "tags": []
   },
   "source": [
    "for i in range(len(out_target)):\n",
    "    with open(\"./xai_log.txt\", \"a\") as f:\n",
    "        out, grad, target, name = out_target[i]\n",
    "        s = \"out: \" + str(out.item()) + \", target: \" + str(target.item()) + \", filename \" + name.replace(\"//\", \"/\") + \"\\n\"\n",
    "        f.write(s)\n",
    "        plot_relevance(grad) \n",
    "        img = plt.imread(name)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        print(s)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d0541234-e607-4c77-9949-66b2ba8fc006",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-15T12:39:04.623666Z",
     "start_time": "2024-07-15T12:38:24.969236Z"
    }
   },
   "source": [
    "from restructure import find_a_ref, restructure_model\n",
    "import copy\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[zen.torchvision.ResNetCanonizer()])\n",
    "\n",
    "out_target = []\n",
    "print(len(loader))\n",
    "for i in range(len(loader)):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    model_copy = copy.deepcopy(res18_ice)\n",
    "    x, y = get_coords_from_name(data_dir,patient,os.path.basename(name))\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy.gene1, torch.tensor(0), in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_ice, grad_ice = attributor(input)\n",
    "        if grad_ice.count_nonzero() == 0:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "    model_copy = copy.deepcopy(res18_no_ice)\n",
    "    \n",
    "    #ref = find_a_ref(model_copy)\n",
    "    \n",
    "    gene1 = restructure_model(model_copy.gene1, torch.tensor(0), in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_no_ice, grad_no_ice = attributor(input)\n",
    "        if grad_no_ice.count_nonzero() == 0:\n",
    "            continue\n",
    "            \n",
    "    \"\"\"\n",
    "    model_copy = copy.deepcopy(sequential_ice).to(\"cpu\")\n",
    "    #model_copy.to(device)\n",
    "\n",
    "    flood = find_a_ref(model_copy, input.to(\"cpu\"), y_ref=0, method='flood', step_width=0.005, max_it=10e4, normalize_top=False)\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy, flood, in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_flood0, grad_flood0 = attributor(input)\n",
    "        if grad_cpy.count_nonzero() == 0:\n",
    "            continue\n",
    "            \n",
    "    model_copy = copy.deepcopy(sequential_no_ice)\n",
    "    model_copy.to(device)\n",
    "    \n",
    "    flood = find_a_ref(model_copy, input, y_ref=target, method='flood', step_width=0.005, max_it=10e4, normalize_top=False)\n",
    "    #ref = find_a_ref(model_copy)\n",
    "    gene1 = restructure_model(model_copy.gene1, flood, in_layer=-3, out_layer=-1)\n",
    "    model_copy.gene1 = gene1\n",
    "    model_copy.to(device)\n",
    "    with Gradient(model_copy, composite) as attributor:\n",
    "        out_flood_tar, grad_flood_tar = attributor(input)\n",
    "        if grad_cpy.count_nonzero() == 0:\n",
    "            continue\n",
    "    \n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out_ori, grad_ori = attributor(input)\n",
    "        if grad_ori.count_nonzero() == 0:\n",
    "            continue\n",
    "    \"\"\"\n",
    "    \n",
    "    out_target.append((out_ice, out_no_ice, grad_ice, grad_no_ice, target, x, y, name))\n",
    "\n",
    "images = []\n",
    "coords = []\n",
    "for i in range(len(out_target)):\n",
    "    with open(\"./xai_log.txt\", \"a\") as f:\n",
    "        out_ice, out_no_ice, grad_ice, grad_no_ice, target, x, y, name = out_target[i]\n",
    "        s = \"out_ref0: \" + str(out_ice.item()) + \", out_tar: \" + str(out_no_ice.item()) + \", target: \" + str(target.item()) + \", filename: \" + os.path.basename(name.replace(\"//\", \"/\")) + \"\\n\"\n",
    "        f.write(s)\n",
    "        #plot_relevance(grad_ice)\n",
    "        \n",
    "        img = plt.imread(name)\n",
    "        images.append(img)\n",
    "        coords.append([x-112,x+112,y-112,y+112])\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        print(s)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4047\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 36.25 GB, other allocations: 13.98 MB, max allowed: 36.27 GB). Tried to allocate 9.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m model_copy\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Gradient(model_copy, composite) \u001B[38;5;28;01mas\u001B[39;00m attributor:\n\u001B[0;32m---> 16\u001B[0m     out_ice, grad_ice \u001B[38;5;241m=\u001B[39m \u001B[43mattributor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m grad_ice\u001B[38;5;241m.\u001B[39mcount_nonzero() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/attribution.py:180\u001B[0m, in \u001B[0;36mAttributor.__call__\u001B[0;34m(self, input, attr_output)\u001B[0m\n\u001B[1;32m    177\u001B[0m     attr_output_fn \u001B[38;5;241m=\u001B[39m attr_output\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomposite \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomposite\u001B[38;5;241m.\u001B[39mhandles:\n\u001B[0;32m--> 180\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr_output_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;28minput\u001B[39m, attr_output_fn)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/attribution.py:286\u001B[0m, in \u001B[0;36mGradient.forward\u001B[0;34m(self, input, attr_output_fn)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# create a view of input in case it does not already requires grad\u001B[39;00m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mview_as(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr_output_fn\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/attribution.py:256\u001B[0m, in \u001B[0;36mGradient.grad\u001B[0;34m(self, input, attr_output_fn)\u001B[0m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    255\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m--> 256\u001B[0m gradient, \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mattr_output_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output, gradient\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/autograd/__init__.py:412\u001B[0m, in \u001B[0;36mgrad\u001B[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001B[0m\n\u001B[1;32m    408\u001B[0m     result \u001B[38;5;241m=\u001B[39m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(\n\u001B[1;32m    409\u001B[0m         grad_outputs_\n\u001B[1;32m    410\u001B[0m     )\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 412\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m materialize_grads:\n\u001B[1;32m    422\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[1;32m    423\u001B[0m         result[i] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tensor_like(inputs[i])\n\u001B[1;32m    424\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(inputs))\n\u001B[1;32m    425\u001B[0m     ):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/core.py:387\u001B[0m, in \u001B[0;36mHook.pre_forward.<locals>.wrapper\u001B[0;34m(grad_input, grad_output)\u001B[0m\n\u001B[1;32m    385\u001B[0m hook \u001B[38;5;241m=\u001B[39m hook_ref()\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m hook\u001B[38;5;241m.\u001B[39mactive:\n\u001B[0;32m--> 387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstored_tensors\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgrad_output\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/core.py:532\u001B[0m, in \u001B[0;36mBasicHook.backward\u001B[0;34m(self, module, grad_input, grad_output)\u001B[0m\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m in_mod, param_mod, out_mod \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_modifiers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_modifiers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_modifiers):\n\u001B[1;32m    531\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m in_mod(original_input)\u001B[38;5;241m.\u001B[39mrequires_grad_()\n\u001B[0;32m--> 532\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ParamMod\u001B[38;5;241m.\u001B[39mensure(param_mod)(module) \u001B[38;5;28;01mas\u001B[39;00m modified, torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[1;32m    533\u001B[0m         output \u001B[38;5;241m=\u001B[39m modified\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    534\u001B[0m         output \u001B[38;5;241m=\u001B[39m out_mod(output)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/contextlib.py:135\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/core.py:327\u001B[0m, in \u001B[0;36mParamMod.__call__\u001B[0;34m(self, module)\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m param \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    326\u001B[0m                 stored_params[key] \u001B[38;5;241m=\u001B[39m param\n\u001B[0;32m--> 327\u001B[0m                 \u001B[38;5;28msetattr\u001B[39m(module, key, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mParameter(\u001B[43mmodifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m module\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/core.py:231\u001B[0m, in \u001B[0;36mzero_wrap.<locals>.zero_params_wrapper.<locals>.modifier_wrapper\u001B[0;34m(input, name)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(zero_params, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;241m==\u001B[39m zero_params \u001B[38;5;129;01mor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m zero_params:\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mzeros_like(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m--> 231\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodifier\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/zennit/rules.py:60\u001B[0m, in \u001B[0;36mClampMod.__init__.<locals>.modifier\u001B[0;34m(param, name)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmodifier\u001B[39m(param, name):\n\u001B[0;32m---> 60\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclamp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 36.25 GB, other allocations: 13.98 MB, max allowed: 36.27 GB). Tried to allocate 9.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for extend, img in zip(coords, images):\n",
    "    ax.imshow(img, extend=extend)"
   ],
   "id": "c20929fc2366ce6"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81ba6425-713e-4f44-ac04-53db15a6afb4",
   "metadata": {},
   "source": [
    "model_copy.to(device)\n",
    "y_t_ = model_copy.forward(input)\n",
    "a_ref_ = model_copy[:-1](input)\n",
    "b_ref_ = model_copy(input)[:-1]\n",
    "c_ref_ = model_copy(input)\n",
    "\n",
    "\n",
    "\n",
    "print(a_ref_)\n",
    "print(b_ref_)\n",
    "print(c_ref_)\n",
    "print(c_ref_[:-1])\n",
    "xxx = [\"a\"]\n",
    "print(xxx[:-1] and xxx[-1])\n",
    "\n",
    "#print(y_t_.item(), \" \", a_ref_.item())\n",
    "#model_copy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5d626098ed07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:21:01.283590Z",
     "start_time": "2024-07-04T12:21:01.275835Z"
    }
   },
   "source": [
    "log = False\n",
    "def module_map_orig(ctx, name, module):\n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        return None\n",
    "\n",
    "    # count the number of the leaves processed yet in 'leafnum'\n",
    "    if 'leafnum' not in ctx:\n",
    "        ctx['leafnum'] = 0\n",
    "    else:\n",
    "        ctx['leafnum'] += 1\n",
    "\n",
    "    # the first 10 leaf-modules which are of type Linear should be assigned\n",
    "    # the Alpha2Beta1 rule\n",
    "    if ctx['leafnum'] < 10:\n",
    "        if log:\n",
    "            print(type(module), \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "        return AlphaBeta(alpha=2, beta=1)\n",
    "    if log:\n",
    "        print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "    # all other rules should be assigned Epsilon\n",
    "    return Epsilon(epsilon=1e-3)\n",
    "\n",
    "\n",
    "def module_map_debug(ctx, name, module):\n",
    "    if type(module) is MyNet:             return None\n",
    "    if type(module) is ResNet:            return None\n",
    "    if type(module) is ReLU:              return None\n",
    "    if type(module) is Sequential:        return None\n",
    "    if type(module) is VGG:               return None\n",
    "    if type(module) is MaxPool2d:         return None\n",
    "    if type(module) is Dropout:           return None\n",
    "    if type(module) is AdaptiveAvgPool2d: return None\n",
    "    \n",
    "    if type(module) is Conv2d:            return Epsilon(epsilon=1e-3)\n",
    "    if type(module) is Linear:\n",
    "        # count the number of the leaves processed yet in 'leafnum'\n",
    "        if 'leafnum' not in ctx:\n",
    "            ctx['leafnum'] = 0\n",
    "        else:\n",
    "            ctx['leafnum'] += 1\n",
    "        if ctx['leafnum'] < 10:\n",
    "            if log:\n",
    "                print(type(module), \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "            return AlphaBeta(alpha=2, beta=1)\n",
    "        if log:\n",
    "            print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "        return Epsilon(epsilon=1e-3)\n",
    "    \n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "    if log:\n",
    "        print(type(module), \" isinstance(Linear): \", isinstance(module, Linear))\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "def module_map_my_net_debug(ctx, name, module):\n",
    "    if type(module) is MyNet:      return None\n",
    "    if type(module) is ResNet:     return None\n",
    "    if type(module) is ReLU:       return None\n",
    "    if type(module) is Sequential: return None\n",
    "    \n",
    "    if type(module) is Conv2d:     return Epsilon(epsilon=1e-3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # check whether there is at least one child, i.e. the module is not a leaf\n",
    "    try:\n",
    "        next(module.children())\n",
    "    except StopIteration:\n",
    "        # StopIteration is raised if the iterator has no more elements,\n",
    "        # which means in this case there are no children and module is a leaf\n",
    "        pass\n",
    "    else:\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        # if StopIteration is not raised on the first element, module is not a leaf\n",
    "        return None\n",
    "    # if the module is not Linear, we do not want to assign a hook\n",
    "    if not isinstance(module, Linear):\n",
    "        if log:\n",
    "            print(type(module), \" -> None\")\n",
    "        return None\n",
    "\n",
    "    # count the number of the leaves processed yet in 'leafnum'\n",
    "    if 'leafnum' not in ctx:\n",
    "        ctx['leafnum'] = 0\n",
    "    else:\n",
    "        ctx['leafnum'] += 1\n",
    "\n",
    "    # the first 10 leaf-modules which are of type Linear should be assigned\n",
    "    # the Alpha2Beta1 rule\n",
    "    if ctx['leafnum'] < 10:\n",
    "        if log:\n",
    "            print(\"leafnum \", ctx['leafnum'], type(module) , \" -> AlphaBeta(alpha=2, beta=1)\")\n",
    "        return AlphaBeta(alpha=2, beta=1)\n",
    "    if log:\n",
    "        print(type(module), \" -> Epsilon(epsilon=1e-3)\")\n",
    "    # all other rules should be assigned Epsilon\n",
    "    return Epsilon(epsilon=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291426a156f5df53",
   "metadata": {},
   "source": [
    "print(grad.shape)\n",
    "print(grad.squeeze().shape)\n",
    "r = plt.imread(filename)\n",
    "print(r.shape)\n",
    "plot_relevance(None, filename)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164ed632cbccc84",
   "metadata": {},
   "source": [
    "for i in range (len(out_target)):\n",
    "    out, grad, target, name = out_target[i]\n",
    "    print(target)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde235f704575e0",
   "metadata": {},
   "source": [
    "out, grad, target, name = out_target[1]\n",
    "print(name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd0c4ddfa2dfa",
   "metadata": {},
   "source": [
    "class ResNetCanonizer(zen.torchvision.CompositeCanonizer):\n",
    "    '''Canonizer for torchvision.models.resnet* type models. This applies SequentialMergeBatchNorm, as well as\n",
    "    add a Sum module to the Bottleneck modules and overload their forward method to use the Sum module instead of\n",
    "    simply adding two tensors, such that forward and backward hooks may be applied.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__((\n",
    "            zen.torchvision.SequentialMergeBatchNorm(),\n",
    "            zen.torchvision.ResNetBottleneckCanonizer(),\n",
    "            zen.torchvision.ResNetBasicBlockCanonizer(),\n",
    "        ))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab2e9805e3c790",
   "metadata": {},
   "source": [
    "newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model_drop = models.resnet50(pretrained=True)\n",
    "print(newmodel)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2926ba9d53d64a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:06:24.232178Z",
     "start_time": "2024-07-15T12:06:19.796859Z"
    }
   },
   "source": [
    "vgg = models.vgg16()\n",
    "res = models.resnet50()\n",
    "current_model = res18_ice\n",
    "img, target, filename = get_img_target_name(loader, device, 2)\n",
    "\n",
    "can_res = zen.torchvision.ResNetCanonizer()\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[can_res])\n",
    "\n",
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(current_model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))\n",
    "\n",
    "\n",
    "#relevance_and_plot(current_model.to(device), module_map_debug, composite, img)\n",
    "#print(\"target: \", target)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7d28b7-7d70-46ba-84f6-f166522b3dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:20:10.390485Z",
     "start_time": "2024-07-04T12:20:03.034437Z"
    }
   },
   "source": [
    "vgg = models.vgg16()\n",
    "res = models.resnet50()\n",
    "current_model = res18_ice\n",
    "img, target, filename = get_img_target_name(loader, device, 2)\n",
    "\n",
    "can_res = zen.torchvision.ResNetCanonizer()\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[can_res])\n",
    "\n",
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(model, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))\n",
    "\n",
    "\n",
    "#relevance_and_plot(current_model.to(device), module_map_debug, composite, img)\n",
    "#print(\"target: \", target)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2443ce42-31ca-4589-8713-721705e3a9b8",
   "metadata": {},
   "source": [
    "out_target = []\n",
    "for i in range(20):\n",
    "    input, target, name = get_img_target_name(loader,device,i)\n",
    "    with Gradient(sequential, composite) as attributor:\n",
    "        out, grad = attributor(input)\n",
    "        if grad.count_nonzero() == 0:\n",
    "            continue\n",
    "        out_target.append((out, grad, target, name))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f8db01c046bfc",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd58e78402a494f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174457c6d87dd1c",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

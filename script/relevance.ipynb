{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T08:50:30.667485Z",
     "start_time": "2024-08-15T08:50:28.027955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from script.data_loader import get_patient_loader\n",
    "import zennit as zen\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "\n",
    "from script.model import get_res18_ciga, get_res50_dropout\n",
    "from script.relevance import plot_relevance,get_attributions_from_loader\n",
    "import matplotlib.pyplot as plt\n",
    "from script.plot_and_print import plot_data_mapped, print_metrics, plot_data_scatter\n",
    "from script.process_csv import generate_results, merge_data\n",
    "from script.data_loader import get_data_loaders\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchvision\n"
   ],
   "id": "f40286b3-2199-475a-a984-beea7035303e",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T08:50:31.472268Z",
     "start_time": "2024-08-15T08:50:30.668464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "path = \"../models/res18/res18_not_iced_e29.pt\"\n",
    "res18_no_ice = get_res18_ciga(path).to(device)\n",
    "path = \"../models/res18/RUBCNL_HLR_Res18_optim_ice/15072024_ep_29_lr_0.0005resnet.pt\"\n",
    "res18_ice    = get_res18_ciga(path).to(device)\n",
    "res18_ice.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "path = \"../models/res18/res18_iced_e29.pt\"\n",
    "res18    = get_res18_ciga(path).to(device)\n",
    "path = \"../models/res50/RUBCNL_HLR_Res50_Drop/24072024_ep_29_lr_0.0005resnet.pt\"\n",
    "res50_drop = get_res50_dropout(path)\n",
    "\n",
    "data_dir = \"../Training_Data/\"\n",
    "patient = \"/p020\"\n",
    "base_path = data_dir+patient+\"/Preprocessed_STDataset/\"\n",
    "merge = pd.read_csv(base_path + \"merge.csv\")\n",
    "loader = get_patient_loader(data_dir, patient)"
   ],
   "id": "4002c006-1172-46f4-8006-9fd200980023",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train, val = get_data_loaders(data_dir,64, )\n",
    "for images, labels, name in train:    \n",
    "    print(images.shape)\n",
    "    break"
   ],
   "id": "a63b925af51e5222",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# drop dropout layers so that restructuring works as that function requires lin relu lin as the upper layers\n",
    "res50_drop_copy = copy.deepcopy(res50_drop)\n",
    "print(res50_drop_copy.gene1)\n",
    "idx = [0,2,3]\n",
    "res50_drop_copy.gene1 = nn.Sequential(*[res50_drop_copy.gene1[i] for i in idx])\n",
    "print(res50_drop_copy.gene1)\n"
   ],
   "id": "49fe71560884d69a",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "can_res = zen.torchvision.ResNetCanonizer()\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[can_res])\n",
    "# out, out_orig, grad, target, x, y, name\n",
    "res50_drop.eval()\n",
    "out_target = get_attributions_from_loader(res50_drop_copy.to(device), loader, device, data_dir, patient, composite, -1, 20)"
   ],
   "id": "2926ba9d53d64a1d",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 48,
   "source": "from script.relevance import get_img_target_name",
   "id": "ba0a61bdbfa07423",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 62,
   "source": "print(len(out_target))",
   "id": "eb867f79b14e13af",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T08:08:35.772170Z",
     "start_time": "2024-07-26T08:08:35.758390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img, target, name = get_img_target_name(loader, device, 0)\n",
    "print(img.shape)"
   ],
   "id": "5d4ec1a54fa37689",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T08:08:36.364344Z",
     "start_time": "2024-07-26T08:08:36.361504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_and_plot_patient(model, device, criterion, data_dir, patient, gene = \"RUBCNL\", results_filename = \"results.csv\"):\n",
    "    generate_results(model, device, criterion, data_dir, patient, gene, results_filename)\n",
    "    merge_data(data_dir, patient, results_filename)\n",
    "    plot_data_mapped(data_dir, patient, \"labels\")\n",
    "    plot_data_mapped(data_dir, patient, \"output\")\n",
    "    plot_data_mapped(data_dir, patient, \"diff\")\n",
    "    plot_data_scatter(data_dir, patient, gene)\n",
    "    print_metrics(data_dir, patient, \"mean\")\n",
    "    print_metrics(data_dir, patient, \"std\")\n",
    "    print_metrics(data_dir, patient, \"pearson\")\n",
    "    \n",
    "    print(\"----------------------------------------\")"
   ],
   "id": "be5f4a0a050cffef",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T08:19:16.417797Z",
     "start_time": "2024-07-26T08:16:39.680980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "process_and_plot_patient(res50_drop_copy,       device, criterion, data_dir, patient, \"RUBCNL\", results_filename = \"slim_model_results.csv\")\n",
    "process_and_plot_patient(res50_drop.to(device), device, criterion, data_dir, patient, \"RUBCNL\", results_filename = \"slim_model_results.csv\")\n"
   ],
   "id": "bc18c28a5646bc4e",
   "execution_count": 53,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T08:23:44.275516Z",
     "start_time": "2024-07-26T08:23:44.245790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[zen.torchvision.ResNetCanonizer()])\n",
    "\n",
    "images = []\n",
    "coords = []\n",
    "for i in range(len(out_target)):\n",
    "    with open(\"xai_log.txt\", \"a\") as f:\n",
    "        out, out_orig, out_orig_restructured, grad, target, x, y, name = out_target[i]\n",
    "        s = \"out: \" + str(out.item()) + \", out_orig: \" + str(out_orig.item()) + \", out_orig_restructured: \" + str(out_orig_restructured.item()) + \", target: \" + str(target.item()) + \", filename: \" + os.path.basename(name.replace(\"//\", \"/\")) + \"\\n\"\n",
    "        f.write(s)\n",
    "        import cv2\n",
    "        img = cv2.imread(name)\n",
    "        \n",
    "        #img = plt.imread(name)\n",
    "        coords.append([x-112,x+112,y-112,y+112])\n",
    "        \n",
    "        img_tns = torch.tensor(img)\n",
    "        img_tns_rs=img_tns.permute(2, 1, 0)\n",
    "        transform = v2.Resize((50, 50), interpolation=torchvision.transforms.InterpolationMode.BICUBIC)\n",
    "        \n",
    "        #print(transform(channel_0).shape)\n",
    "        img_out = transform(img_tns_rs)\n",
    "        assert(img_out.shape == (3,50,50))\n",
    "        torch.save(img_out, \"../xai/relevance_scaled_tiles\" + patient + \"/\" + os.path.basename(name)[:-4] + \"pt\")"
   ],
   "id": "d0541234-e607-4c77-9949-66b2ba8fc006",
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:21:52.595797Z",
     "start_time": "2024-07-26T11:21:49.694363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[zen.torchvision.ResNetCanonizer()])\n",
    "\n",
    "images = []\n",
    "coords = []\n",
    "for i in range(len(out_target)):\n",
    "    out, out_orig, out_orig_restructured, grad, target, x, y, name = out_target[i]\n",
    "    s = \"out: \" + str(out.item()) + \", out_orig: \" + str(out_orig.item()) + \", out_orig_restructured: \" + str(out_orig_restructured.item()) + \", target: \" + str(target.item()) + \", filename: \" + os.path.basename(name.replace(\"//\", \"/\")) + \"\\n\"\n",
    "    print(s)\n",
    "    plot_relevance(grad)\n",
    "    print(name)\n",
    "    from PIL import Image\n",
    "    img = Image.open(name)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ],
   "id": "31c9307d812d6546",
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T08:54:38.000852Z",
     "start_time": "2024-07-30T08:54:37.998498Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(loader))",
   "id": "4cbe516fc88222d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:52:36.713547Z",
     "start_time": "2024-07-26T11:52:36.352412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import copy\n",
    "composite = zen.composites.EpsilonPlusFlat(canonizers=[zen.torchvision.ResNetCanonizer()])\n",
    "\n",
    "images = []\n",
    "coords = []\n",
    "print(patient)\n",
    "for i in range(len(loader)):\n",
    "    with open(\"xai_log.txt\", \"a\") as f:\n",
    "        out_target = get_attributions_from_loader(res50_drop_copy, loader, device, data_dir, patient, composite, i, -1)\n",
    "\n",
    "        out, out_orig, out_orig_restructured, grad, target, x, y, name = out_target[0]\n",
    "        print(y)\n",
    "        break\n",
    "        s = \"out: \" + str(out.item()) + \", out_orig: \" + str(out_orig.item()) + \", out_orig_restructured: \" + str(out_orig_restructured.item()) + \", target: \" + str(target.item()) + \", filename: \" + os.path.basename(name.replace(\"//\", \"/\")) + \"\\n\"\n",
    "        f.write(s)\n",
    "        #plot_relevance(grad)\n",
    "        #print(grad.shape)\n",
    "        import cv2\n",
    "        img = cv2.imread(name)\n",
    "        \n",
    "        #img = plt.imread(name)\n",
    "        coords.append([x-112,x+112,y-112,y+112])\n",
    "        \n",
    "        img_tns = torch.tensor(img)\n",
    "        img_tns_rs=img_tns.permute(2, 1, 0)\n",
    "        transform = v2.Resize((50, 50), interpolation=torchvision.transforms.InterpolationMode.BICUBIC)\n",
    "        \n",
    "        #print(transform(channel_0).shape)\n",
    "        img_out = transform(img_tns_rs)\n",
    "        assert(img_out.shape == (3,50,50))\n",
    "        torch.save(img_out, \"../xai/relevance_scaled_tiles\" + patient + \"/\" + os.path.basename(name)[:-4] + \"pt\")\n"
   ],
   "id": "8679e27de4bf0bf9",
   "execution_count": 98,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:15:04.374748Z",
     "start_time": "2024-07-23T13:15:03.819587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len(coords)\n",
    "coords_fixed = []\n",
    "for _, (a,b,c,d) in enumerate(coords):\n",
    "    coords_fixed.append((a+87, b-87, c+87, d-87))\n",
    "    "
   ],
   "id": "d539e89211217f14",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:15:19.689325Z",
     "start_time": "2024-07-23T13:15:19.687271Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(coords_fixed))",
   "id": "71103e92e181e6e6",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:21:56.535866Z",
     "start_time": "2024-07-23T13:21:54.114501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imgs = []\n",
    "for i in range(int(len(loader)/2)):\n",
    "    img, target, name = loader[i]\n",
    "    out = torch.load(\"../xai/relevance_scaled_tiles\" + patient + \"/\" + os.path.basename(name)[:-4] + \"pt\")\n",
    "    imgs.append(out)"
   ],
   "id": "4cb7908fbb8ca9f3",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:42:08.281406Z",
     "start_time": "2024-07-26T11:42:08.279455Z"
    }
   },
   "cell_type": "code",
   "source": "coords_half = coords[:int(len(loader)/2)]",
   "id": "a5ecc7a661388ea8",
   "execution_count": 80,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:42:10.443177Z",
     "start_time": "2024-07-26T11:42:10.440609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(len(imgs))\n",
    "print(len(coords_half))\n"
   ],
   "id": "8a127680cf475f0a",
   "execution_count": 81,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:46:25.155218Z",
     "start_time": "2024-07-26T11:46:25.065233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "coords_half_copy = copy.deepcopy(coords_half)\n",
    "for i, c in enumerate(coords_half_copy):\n",
    "    coords_half_copy[i] = [tuple(x.to_list()) for x in c]"
   ],
   "id": "9b423ad69cb3af93",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T11:46:26.552175Z",
     "start_time": "2024-07-26T11:46:26.548663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(coords_half[0][0]))\n",
    "print(coords_half[0])\n",
    "print(type(coords[0][0]))\n",
    "print(coords[0])\n",
    "print(type(coords_half_copy[0][0]))\n",
    "print(coords_half_copy[0])\n"
   ],
   "id": "ed19342510183d8",
   "execution_count": 91,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:48:40.931983Z",
     "start_time": "2024-07-23T19:48:40.830518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for extent, img in zip(coords_half, imgs):\n",
    "    img = img.permute(2,1,0)\n",
    "    print(extent)\n",
    "    print(type(extent[0]))\n",
    "    extend = [extent]\n",
    "    print(type(extend))\n",
    "    ax.imshow(img, extent=extent)\n",
    "    break"
   ],
   "id": "6626925adb3b2022",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T12:42:18.426943Z",
     "start_time": "2024-07-23T12:42:18.370219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "img_tns = torch.tensor(img)\n",
    "print(img_tns.shape)\n",
    "img_tns_rs=img_tns.permute(2, 1, 0)\n",
    "print(img_tns_rs.shape)\n",
    "#channel_0 = img_tns_rs[0].unsqueeze(0)\n",
    "#print(channel_0.unsqueeze(0).shape)\n",
    "\n",
    "#t = torchvision.transforms.Grayscale()\n",
    "#tns_grey = t(img_tns_rs)\n",
    "#print(img_tns_rs.shape)\n",
    "transform = v2.Resize((50, 50), interpolation=torchvision.transforms.InterpolationMode.BICUBIC)\n",
    "\n",
    "#print(transform(channel_0).shape)\n",
    "img_out = transform(img_tns_rs)\n",
    "print(img_out.shape)\n",
    "plt.imshow(img_out.permute(2,1,0))"
   ],
   "id": "3b382cfc83df73da",
   "execution_count": 75,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T12:41:10.201405Z",
     "start_time": "2024-07-23T12:41:10.185604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('path_to_your_image.jpg')\n",
    "\n",
    "# Define the transform to resize the image\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((50, 50)),  # Resize to 50x50\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "resized_image = resize_transform(image)"
   ],
   "id": "a85c7d82fb67d1cd",
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1174457c6d87dd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T12:32:50.672672Z",
     "start_time": "2024-07-23T12:32:50.549534Z"
    }
   },
   "source": "plt.imshow(tns_grey.reshape(-1,156,1))",
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T12:24:48.546633Z",
     "start_time": "2024-07-23T12:24:48.464084Z"
    }
   },
   "cell_type": "code",
   "source": "plt.imshow(img_out)\n",
   "id": "51d1a019c1292e1a",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "12951e06bf1200f",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

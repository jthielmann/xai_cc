{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:04:08.079790Z",
     "start_time": "2024-09-19T09:04:08.076099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import zennit\n",
    "from zennit.torchvision import VGGCanonizer\n",
    "from zennit.composites import EpsilonPlusFlat\n",
    "from crp.attribution import CondAttribution\n",
    "from crp.concepts import ChannelConcept\n",
    "from crp.helper import get_layer_names\n",
    "from crp.visualization import FeatureVisualization\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n"
   ],
   "id": "765d60e420dc8e0f",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:04:09.572128Z",
     "start_time": "2024-09-19T09:04:08.459659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_loader import get_dataset\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "model = vgg16(weights=\"IMAGENET1K_V1\")\n",
    "model.eval()\n",
    "model = model.to()\n",
    "data_dir = \"../Training_Data/\"\n",
    "dataset = get_dataset(data_dir)\n",
    "from torchvision import transforms\n",
    "\n",
    "class STDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, device=\"mps\", transforms=transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            # mean and std of the whole dataset\n",
    "            transforms.Normalize([0.7406, 0.5331, 0.7059], [0.1651, 0.2174, 0.1574])\n",
    "            ])):\n",
    "        self.dataframe = dataframe\n",
    "        self.transforms = transforms\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        gene_names = list(self.dataframe)[1:]\n",
    "        gene_vals = []\n",
    "        row = self.dataframe.iloc[index]\n",
    "        a = Image.open(row[\"tile\"]).convert(\"RGB\")\n",
    "        # print(x.size)\n",
    "        for j in gene_names:\n",
    "            gene_val = float(row[j])\n",
    "            gene_vals.append(gene_val)\n",
    "        e = row[\"tile\"]\n",
    "        # apply normalization transforms as for pretrained colon classifier\n",
    "        a = self.transforms(a)\n",
    "        a = a.to(self.device)\n",
    "        return a, 0\n",
    "datasetST = STDataset(dataset)\n",
    "attribution = CondAttribution(model)\n",
    "composite = EpsilonPlusFlat(canonizers=[VGGCanonizer()])\n"
   ],
   "id": "15578ea64987cadd",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T09:13:19.250211Z",
     "start_time": "2024-09-19T09:04:10.121910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_names = get_layer_names(model, [torch.nn.Conv2d])\n",
    "layer_map = {layer: ChannelConcept() for layer in layer_names}\n",
    "\n",
    "\n",
    "preprocessing =  T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "fv = FeatureVisualization(attribution, datasetST, layer_map, preprocess_fn=preprocessing, path=f\"../crp_out/tmp\")\n",
    "fv.run(composite, 0, len(dataset) // 1, batch_size=32) # needs to be run only once\n",
    "print(\"CRP preprocessing done.\")\n",
    "\n"
   ],
   "id": "e6559aba14daade8",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "df2daa1af34198fc",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

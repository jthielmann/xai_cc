{
 "cells": [
  {
   "cell_type": "code",
   "id": "8b4808e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:19:57.892310Z",
     "start_time": "2024-07-04T12:19:55.473309Z"
    }
   },
   "source": [
    "# import required libraries\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from restructure import *\n",
    "from func import *"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "503a1b98",
   "metadata": {},
   "source": [
    "### limitations/ edge cases of the flooding rule:\n",
    "\n",
    "-  if the model[-1].bias > y_ref, then y_ref never will be reached.\n",
    "-  a large stepwith can result in poor a_refs.\n",
    "-  top_layer normalization (rescale-top) was not introduced in [1] but we found that it can be helpful to generate more faithful explanations.\n",
    "-  the flooding rule does not ensure that the offset found lays within the distribution of activations, especially when y_ref>>y.\n",
    "-  an asymetric treatment of activations based on their respective weights in the last layer can be reasonable (for example in section VI. A)."
   ]
  },
  {
   "cell_type": "code",
   "id": "00fa15a4-4542-40fa-a720-56cd729e7bce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:19:58.489223Z",
     "start_time": "2024-07-04T12:19:57.893844Z"
    }
   },
   "source": [
    "model_path = '../currentModel/model.pt'\n",
    "\n",
    "# Load\n",
    "device = torch.device('cpu')\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "706e6333-2256-42fe-a51b-2a33508eddd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:19:58.490117Z",
     "start_time": "2024-07-04T12:19:58.490045Z"
    }
   },
   "source": [
    "data_dir='../Training_Data/'\n",
    "batch_size=64\n",
    "gene=\"RUBCNL\"\n",
    "criterion=nn.MSELoss()\n",
    "learning_rate= 0.00001\n",
    "optimizer = optim.AdamW([{\"params\": model.pretrained.parameters(), \"lr\": learning_rate},\n",
    "                        {\"params\": model.my_new_layers.parameters(), \"lr\": learning_rate}], weight_decay=0.005)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b45382c-337f-46c8-943b-72cb42a402d4",
   "metadata": {},
   "source": [
    "train_loader, val_loader = get_data_loaders(data_dir, batch_size, gene)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818ad09-15a4-4ddc-8a06-b6075bb924f3",
   "metadata": {},
   "source": [
    "def train_epoch_tmp(resnet, device, dataloader, criterion, optimizer):\n",
    "    train_loss = 0.0\n",
    "    batch_corr_train = 0.0\n",
    "    resnet.train()\n",
    "    i = 0\n",
    "    for images, labels, path in dataloader:\n",
    "        if i % 20 == 0:\n",
    "            print(\"train_epoch iteration \", i)\n",
    "        i+=1\n",
    "        images = images.to(device)\n",
    "        images = images.float()\n",
    "\n",
    "        labels = torch.stack(labels, dim=1)\n",
    "        labels = labels.float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        g_output = resnet(images)\n",
    "        loss = criterion(g_output, labels)\n",
    "        if i % 1000 == 0:\n",
    "            print(\"lost\")\n",
    "        loss.backward()\n",
    "        if i % 1000 == 0:\n",
    "            print(\"backward\")\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        corr = stats.pearsonr(g_output[:, 0].cpu().detach().numpy(), labels[:, 0].cpu().detach().numpy())[0]\n",
    "        batch_corr_train += corr\n",
    "        once = False\n",
    "        return\n",
    "\n",
    "    return train_loss, batch_corr_train\n",
    "train_epoch_tmp(model, device, train_loader, criterion, optimizer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d33b955-0dab-4921-a7ae-4bdf86846756",
   "metadata": {},
   "source": [
    "model_restructured = restructure_model(model.gene1, 0, in_layer=-3, out_layer=-1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a4801b-ddf6-4ff4-99b7-6c552605d30d",
   "metadata": {},
   "source": [
    "print(model_restructured)\n",
    "print(model.gene1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b9b001-a8a4-4d28-940c-2a20d9342bd5",
   "metadata": {},
   "source": [
    "model.gene1 = model_restructured"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9307ef55",
   "metadata": {},
   "source": [
    "# find a_ref\n",
    "\n",
    "i_sample = 60\n",
    "y_ref = 1\n",
    "\n",
    "input_sample = input_[i_sample].reshape(1,-1)\n",
    "output_sample = model(input_sample).detach().numpy()[0][0]\n",
    "\n",
    "plot_setting(model, input_, i_sample, output_sample, y_ref)\n",
    "\n",
    "a_ref = find_a_ref(model, input_sample, y_ref) \n",
    "\n",
    "print(f'a i_sample:     {model[:-1](input_sample)}')\n",
    "print(f'a_ref i_sample: {a_ref}')\n",
    "\n",
    "print(f'y_ with a_ref:  {model[-1:](a_ref)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10baeb",
   "metadata": {},
   "source": [
    "# restructure model\n",
    "\n",
    "model_restructured = restructure_model(model, a_ref, in_layer=-3, out_layer=-1)\n",
    "\n",
    "print(model(input_sample))\n",
    "print(model_restructured(input_sample))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3a8f2b1a",
   "metadata": {},
   "source": [
    "##### The output of the model is reduced by y_ref for sample i. Therefore, explaining the model_restructured for input_sample using the respective LRP rules yields a contextualized explanation relative to y_ref."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35db2ef",
   "metadata": {},
   "source": [
    "Reference: \n",
    "\n",
    "[1] S. Letzgus, P. Wagner, J. Lederer, W. Samek, K.-R. M ̈uller, and G. Montavon. Toward explainable artificial intelligence for regression models: A methodological perspective. IEEE Signal Processing Magazine, 39(4):40–58, 2022."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
